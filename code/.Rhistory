labs(
title = ' \n
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
2.0    22.0    77.0   143.9   189.0  3409.0',
x = 'Call length'
)
?drop_na()
#write.csv(per_call_df, '~/Desktop/PAE/github/data/per_call_df.csv', row.names = FALSE)
#time to content 1
time_to_content<- dplyr::filter(log_data, grepl("INCOMING",logInfo)|grepl("CONTENT PLAYED",logInfo))
time_to_content<- time_to_content%>%
group_by(callId) %>%
mutate(to_content = eventTime - lag(eventTime))
time_to_content <-time_to_content %>%
group_by(callId) %>%
filter(row_number()==2)
ggplot(time_to_content , aes(x=to_content)) +
geom_histogram(color="black", fill="blue") +
xlim(0,400)+
labs(
title = ' \n
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
2.0    22.0    77.0   143.9   189.0  3409.0',
x = 'time to content'
)
ggplot(per_call_per_caller, aes(x=n)) +
geom_histogram(color="black", fill="blue")+
xlim(0,50)
View(per_call_df)
library(tidyverse)
library(dplyr)
library(stringr)
library(svMisc)
library(ggplot2)
library(gtable)
library("ggpubr")
library(data.table)
library(lfe)
library(haven)
#log_data <- read_csv("~/Desktop/PAE/github/data/logData.csv")
log_data <- read_csv("~/Desktop/PAE/github/data/benData_weakCallers.csv")
log_data$logInfo <- toupper(log_data$logInfo)
#creating the unique call column
#getting rid of the duplicate phone hang ups
row_dump <- c()
for (i in 1:length(log_data$logInfo)){
if (str_detect(log_data$logInfo[i], 'HUNG UP')){
if (str_detect(log_data$logInfo[i-1], 'HUNG UP')){
row_dump <- append(row_dump, i)
}
}
else{
log_data$logInfo[i] = log_data$logInfo[i]
}
}
log_data <- log_data %>%
slice(-row_dump)
#creating call Id
counter <-  0
for (i in 1:length(log_data$callId)){
if (str_detect(log_data$logInfo[i], 'INCOMING')){
counter <- counter + 1
log_data$callId[i] <- counter
}
else{
log_data$callId[i] <- counter
}
}
log_data_saver <- log_data
log_data <- unique(log_data)
#MAKE IT ALL UPPER!!!
### GETTING THE DATE MONTH AND YEAR IF I WANT!!!
extractdate <- function(date) {
day <- format(date, format="%d")
month <- format(date, format="%m")
year <- format(date, format="%Y")
cbind(day, month, year)
}
#making first calls
first_call<-extractdate(log_data$callTime)
#making last call
last_day <-substr(log_data$lastCallTime, 9, 10)
last_month <- substr(log_data$lastCallTime, 6, 7)
last_year <-substr(log_data$lastCallTime, 1, 4)
log_data<-cbind(log_data, first_call,last_day,last_month,last_year)
#Converting columns to numeric
log_data$day <-as.numeric(log_data$day)
log_data$last_day <- as.numeric(log_data$last_day)
log_data$month <-as.numeric(log_data$month)
log_data$last_month <- as.numeric(log_data$last_month)
log_data$year <- as.numeric(log_data$year)
log_data$last_year <- as.numeric(log_data$last_year )
log_data$year <- log_data$year +log_data$month/12
log_data$last_year <- log_data$last_year + log_data$last_month/12
log_data$caller_lifetime <- log_data$last_year - log_data$year
library(tidyverse)
library(dplyr)
library(stringr)
library(svMisc)
library(ggplot2)
library(gtable)
library("ggpubr")
library(data.table)
library(lfe)
library(haven)
log_data <- read_csv("~/Desktop/PAE/github/data/logData.csv"
View(log_data)
log_data <- read_csv("~/Desktop/PAE/github/data/logData.csv")
View(log_data)
library(tidyverse)
library(dplyr)
library(stringr)
library(svMisc)
library(ggplot2)
library(gtable)
library("ggpubr")
library(data.table)
library(lfe)
library(haven)
log_data <- read_csv("~/Desktop/PAE/github/data/logData.csv")
#log_data <- read_csv("~/Desktop/PAE/github/data/benData_weakCallers.csv")
#log_data <- read_csv("~/Desktop/benData_weakCallers.csv")
log_data$logInfo <- toupper(log_data$logInfo)
#creating the unique call column
#getting rid of the duplicate phone hang ups
row_dump <- c()
for (i in 1:length(log_data$logInfo)){
if (str_detect(log_data$logInfo[i], 'HUNG UP')){
if (str_detect(log_data$logInfo[i-1], 'HUNG UP')){
row_dump <- append(row_dump, i)
}
}
else{
log_data$logInfo[i] = log_data$logInfo[i]
}
}
library(tidyverse)
library(dplyr)
library(stringr)
library(svMisc)
library(ggplot2)
library(gtable)
library("ggpubr")
library(data.table)
library(lfe)
library(haven)
log_data <- read_csv("~/Desktop/PAE/github/data/logData.csv")
#log_data <- read_csv("~/Desktop/PAE/github/data/benData_weakCallers.csv")
#log_data <- read_csv("~/Desktop/benData_weakCallers.csv")
log_data$logInfo <- toupper(log_data$logInfo)
#creating the unique call column
#getting rid of the duplicate phone hang ups
# row_dump <- c()
#
# for (i in 1:length(log_data$logInfo)){
#   if (str_detect(log_data$logInfo[i], 'HUNG UP')){
#     if (str_detect(log_data$logInfo[i-1], 'HUNG UP')){
#       row_dump <- append(row_dump, i)
#     }
#   }
#   else{
#     log_data$logInfo[i] = log_data$logInfo[i]
#   }
# }
#
# log_data <- log_data %>%
#   slice(-row_dump)
#
# #creating call Id
# counter <-  0
# for (i in 1:length(log_data$callId)){
#   if (str_detect(log_data$logInfo[i], 'INCOMING')){
#     counter <- counter + 1
#     log_data$callId[i] <- counter
#   }
#   else{
#     log_data$callId[i] <- counter
#   }
# }
log_data_saver <- log_data
log_data <- unique(log_data)
#MAKE IT ALL UPPER!!!
### GETTING THE DATE MONTH AND YEAR IF I WANT!!!
extractdate <- function(date) {
day <- format(date, format="%d")
month <- format(date, format="%m")
year <- format(date, format="%Y")
cbind(day, month, year)
}
#making first calls
first_call<-extractdate(log_data$callTime)
#making last call
last_day <-substr(log_data$eventTime, 9, 10)
last_month <- substr(log_data$eventTime, 6, 7)
last_year <-substr(log_data$eventTime, 1, 4)
log_data<-cbind(log_data, first_call,last_day,last_month,last_year)
#Converting columns to numeric
log_data$day <-as.numeric(log_data$day)
log_data$last_day <- as.numeric(log_data$last_day)
log_data$month <-as.numeric(log_data$month)
log_data$last_month <- as.numeric(log_data$last_month)
log_data$year <- as.numeric(log_data$year)
log_data$last_year <- as.numeric(log_data$last_year )
log_data$year <- log_data$year +log_data$month/12
log_data$last_year <- log_data$last_year + log_data$last_month/12
log_data$caller_lifetime <- log_data$last_year - log_data$year
View(log_data)
lang_spoken <- log_data %>%
group_by(callerId, langId) %>%
count()
#Distribution of time difference bewtween first and last call
lifetime<- log_data %>%
group_by(callerId, caller_lifetime) %>%
count()
#distribution of calls made
calls_made <- log_data %>%
group_by(callerId, noCallsMade) %>%
count()
content_listened <- filter(log_data, grepl("CONTENT",logInfo))
content_listened <- filter(content_listened , !grepl("CONTENT MENU",logInfo))
content_listened <- filter(content_listened , !grepl("CONTENT IS NOT AVAILABLE",logInfo))
#Creating a content#_played column
content_listened$content_played <- ifelse(str_detect(content_listened$logInfo, 'CONTENT PLAYED', negate = FALSE),1,0)
content_listened$replay_request <- ifelse(str_detect(content_listened$logInfo, 'CONTENT REPLAY REQUESTED', negate = FALSE),1,0)
content_played<-aggregate(content_listened$content_played,list(content_listened$callerId), FUN=sum)
?rename
content_played <- content_played %>%
dplyr::rename(
con_play = x,
callerId = Group.1
)
content_replay<-aggregate(content_listened$replay_request,list(content_listened$callerId), FUN=sum)
content_replay <- content_replay %>%
dplyr::rename(
con_replay = x,
callerId = Group.1
)
content_counts <- cbind(content_played, content_replay)
content_counts$adjusted_con <- content_counts$con_play-content_counts$con_replay
content_counts$callerId <- NULL
summary(content_counts$adjusted_con)
# Getting the number of calls per person
calls_made <- log_data %>%
dplyr::group_by(callerId, noCallsMade, langId) %>%
count()
#join between tables
content_ratio <- left_join(calls_made, content_counts,by="callerId")
content_ratio[is.na(content_ratio)] <- 0
content_ratio$ratio <- content_ratio$adjusted_con/content_ratio$noCallsMade
# QUICKLY GETTING PER CALL for the average call
tester <- log_data %>%
group_by(callerId, callId) %>%
count()
tester$n <- NULL
tester <- tester%>%
group_by(callerId) %>%
count()
content_list_call <- filter(log_data, grepl("CONTENT",logInfo))
content_list_call <- filter(content_list_call , !grepl("CONTENT MENU",logInfo))
content_list_call <- filter(content_list_call , !grepl("CONTENT IS NOT AVAILABLE",logInfo))
#Creating a content#_played column
content_list_call$content_played <- ifelse(str_detect(content_list_call$logInfo, 'CONTENT PLAYED', negate = FALSE),1,0)
content_list_call$replay_request <- ifelse(str_detect(content_list_call$logInfo, 'CONTENT REPLAY REQUESTED', negate = FALSE),1,0)
content_played<-aggregate(content_list_call$content_played,list(content_list_call$callId), FUN=sum)
?rename
content_played <- content_played %>%
dplyr::rename(
con_play = x,
callId = Group.1
)
content_replay<-aggregate(content_list_call$replay_request,list(content_list_call$callId), FUN=sum)
content_replay <- content_replay %>%
dplyr::rename(
con_replay = x,
callId = Group.1
)
content_counts_call <- cbind(content_played, content_replay)
content_counts_call$adjusted_con <- content_counts_call$con_play-content_counts_call$con_replay
content_counts_call$callId <- NULL
# YOU HAVE TO JOIN BACK TO FIND OUT THE ZERO CONTENT
prediction <- log_data %>%
dplyr::group_by(callerId, noCallsMade, noContentListened,caller_lifetime,
day,month,year,last_day,last_month,last_year) %>%
count()
calls_made_total <- log_data %>%
dplyr::group_by(callId, noCallsMade, noContentListened,caller_lifetime,
day,month,year,last_day,last_month,last_year) %>%
count()
calls_callers <- log_data %>%
dplyr::group_by(callerId, callId, langId) %>%
count()
per_call_df <-  left_join(calls_made_total, content_counts_call,by="callId")
#getting back the call id
per_call_df <-  left_join(per_call_df , calls_callers ,by="callId")
per_call_df[is.na(per_call_df)] <- 0
per_call_df$depth <- per_call_df$n
per_call_df$content <- ifelse(per_call_df$con_play > 0, 1,0)
class(log_data$eventTime[10]-log_data$eventTime[20])
summary(per_call_df$content)
ggplot(per_call_df, aes(x=langId)) +
geom_bar()+
geom_text(stat='count', aes(label=..count../16445), vjust=-1)+
ylim(0,8500)+
labs(
title = 'Distribution of Languages by Call
1 = Amharic, 2=Oromiffa, 3=Tigrigna, 4=Wolayitta, and 5=Sidamigna',
x = 'Language',
y= 'count'
)
per_call_df_copy <- per_call_df
per_call_per_caller <- aggregate(per_call_df$content, by=list(Category=per_call_df$callerId), FUN=sum)
per_call_per_caller$callerId<- per_call_per_caller$Category
per_call_per_caller <- left_join(per_call_per_caller, tester ,by="callerId")
per_call_per_caller$ratio <- round(per_call_per_caller$x/per_call_per_caller$n,2)
#THIS IS THE FINAL RATIO FOR CALLERS REEACHING CONTENT - THE PERCENTAGE OF TIMES A CALLER CALLS AND GETS TO CONTENT!!!!!!!!
summary(per_call_per_caller$ratio)
ggplot(per_call_per_caller, aes(x=ratio))+
geom_histogram(color="black", fill="green", bins=20) +
labs(
title = 'Percentage of Calls ending in Content grouped by caller
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
0.0000  0.2900  0.5000  0.4752  0.6700  1.0000 ',
y='Count',
x='Percentage Reached Content'
)
#Final join to get max possible data
prediction <- log_data %>%
dplyr::group_by(callerId, noCallsMade, noContentListened,caller_lifetime,
day,month,year,last_day,last_month,last_year) %>%
count()
prediction$noCallsMade <- NULL
prediction_df <-  left_join(content_ratio, prediction,by="callerId")
write.csv(prediction_df, '~/Desktop/PAE/github/data/caller_data.csv', row.names = FALSE)
#VERY QUICKLY
View(prediction_df)
call_length <- call_length %>%
drop_na() %>%
select(call_time)
#doing call length
call_length<- dplyr::filter(log_data, grepl("INCOMING",logInfo)|grepl("HUNG",logInfo))
call_length <- call_length %>%
group_by(callId) %>%
mutate(call_time = eventTime - lag(eventTime))
call_length <- call_length %>%
drop_na() %>%
select(call_time)
per_call_df <-  left_join(per_call_df, call_length,by="callId")
per_call_df <- per_call_df %>%
drop_na()
per_call_df <- per_call_df[!duplicated(per_call_df$callId), ]
#write.csv(per_call_df, '~/Desktop/PAE/github/data/per_call_df.csv', row.names = FALSE)
summary(as.numeric(per_call_df$call_time))
ggplot(per_call_df , aes(x=call_time)) +
geom_histogram(color="black", fill="blue") +
xlim(0,1000)+
labs(
title = ' \n
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
2.0    22.0    77.0   143.9   189.0  3409.0',
x = 'Call length'
)
?drop_na()
#write.csv(per_call_df, '~/Desktop/PAE/github/data/per_call_df.csv', row.names = FALSE)
#time to content 1
time_to_content<- dplyr::filter(log_data, grepl("INCOMING",logInfo)|grepl("CONTENT PLAYED",logInfo))
time_to_content<- time_to_content%>%
group_by(callId) %>%
mutate(to_content = eventTime - lag(eventTime))
time_to_content <-time_to_content %>%
group_by(callId) %>%
filter(row_number()==2)
ggplot(time_to_content , aes(x=to_content)) +
geom_histogram(color="black", fill="blue") +
xlim(0,400)+
labs(
title = ' \n
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
2.0    22.0    77.0   143.9   189.0  3409.0',
x = 'time to content'
)
ggplot(per_call_per_caller, aes(x=n)) +
geom_histogram(color="black", fill="blue")+
xlim(0,50)
View(prediction_df)
View(per_call_df)
content_list_call <- filter(log_data, grepl("CONTENT",logInfo))
content_list_call <- filter(content_list_call , !grepl("CONTENT MENU",logInfo))
content_list_call <- filter(content_list_call , !grepl("CONTENT IS NOT AVAILABLE",logInfo))
#Creating a content#_played column
content_list_call$content_played <- ifelse(str_detect(content_list_call$logInfo, 'CONTENT PLAYED', negate = FALSE),1,0)
content_list_call$replay_request <- ifelse(str_detect(content_list_call$logInfo, 'CONTENT REPLAY REQUESTED', negate = FALSE),1,0)
content_played<-aggregate(content_list_call$content_played,list(content_list_call$callId), FUN=sum)
?rename
content_played <- content_played %>%
dplyr::rename(
con_play = x,
callId = Group.1
)
content_replay<-aggregate(content_list_call$replay_request,list(content_list_call$callId), FUN=sum)
content_replay <- content_replay %>%
dplyr::rename(
con_replay = x,
callId = Group.1
)
content_counts_call <- cbind(content_played, content_replay)
content_counts_call$adjusted_con <- content_counts_call$con_play-content_counts_call$con_replay
content_counts_call$callId <- NULL
# YOU HAVE TO JOIN BACK TO FIND OUT THE ZERO CONTENT
prediction <- log_data %>%
dplyr::group_by(callerId, noCallsMade, noContentListened,caller_lifetime,
day,month,year,last_day,last_month,last_year) %>%
count()
calls_made_total <- log_data %>%
dplyr::group_by(callId, noCallsMade, noContentListened,caller_lifetime,
day,month,year,last_day,last_month,last_year) %>%
count()
calls_callers <- log_data %>%
dplyr::group_by(callerId, callId, langId) %>%
count()
per_call_df <-  left_join(calls_made_total, content_counts_call,by="callId")
#getting back the call id
per_call_df <-  left_join(per_call_df , calls_callers ,by="callId")
per_call_df[is.na(per_call_df)] <- 0
per_call_df$depth <- per_call_df$n
per_call_df$content <- ifelse(per_call_df$con_play > 0, 1,0)
class(log_data$eventTime[10]-log_data$eventTime[20])
summary(per_call_df$content)
ggplot(per_call_df, aes(x=langId)) +
geom_bar()+
geom_text(stat='count', aes(label=..count../16445), vjust=-1)+
ylim(0,8500)+
labs(
title = 'Distribution of Languages by Call
1 = Amharic, 2=Oromiffa, 3=Tigrigna, 4=Wolayitta, and 5=Sidamigna',
x = 'Language',
y= 'count'
)
per_call_df_copy <- per_call_df
per_call_per_caller <- aggregate(per_call_df$content, by=list(Category=per_call_df$callerId), FUN=sum)
per_call_per_caller$callerId<- per_call_per_caller$Category
per_call_per_caller <- left_join(per_call_per_caller, tester ,by="callerId")
per_call_per_caller$ratio <- round(per_call_per_caller$x/per_call_per_caller$n,2)
#THIS IS THE FINAL RATIO FOR CALLERS REEACHING CONTENT - THE PERCENTAGE OF TIMES A CALLER CALLS AND GETS TO CONTENT!!!!!!!!
summary(per_call_per_caller$ratio)
ggplot(per_call_per_caller, aes(x=ratio))+
geom_histogram(color="black", fill="green", bins=20) +
labs(
title = 'Percentage of Calls ending in Content grouped by caller
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
0.0000  0.2900  0.5000  0.4752  0.6700  1.0000 ',
y='Count',
x='Percentage Reached Content'
)
#Final join to get max possible data
prediction <- log_data %>%
dplyr::group_by(callerId, noCallsMade, noContentListened,caller_lifetime,
day,month,year,last_day,last_month,last_year) %>%
count()
prediction$noCallsMade <- NULL
prediction_df <-  left_join(content_ratio, prediction,by="callerId")
#write.csv(prediction_df, '~/Desktop/PAE/github/data/caller_data.csv', row.names = FALSE)
#VERY QUICKLY
View(prediction)
View(prediction_df)
write.csv(per_call_df, '~/Desktop/PAE/github/data/caller_data.csv', row.names = FALSE)
View(per_call_df)
#doing call length
call_length<- dplyr::filter(log_data, grepl("INCOMING",logInfo)|grepl("HUNG",logInfo))
call_length <- call_length %>%
group_by(callId) %>%
mutate(call_time = eventTime - lag(eventTime))
call_length <- call_length %>%
drop_na() %>%
select(call_time)
per_call_df <-  left_join(per_call_df, call_length,by="callId")
per_call_df <- per_call_df %>%
drop_na()
per_call_df <- per_call_df[!duplicated(per_call_df$callId), ]
#write.csv(per_call_df, '~/Desktop/PAE/github/data/per_call_df.csv', row.names = FALSE)
summary(as.numeric(per_call_df$call_time))
ggplot(per_call_df , aes(x=call_time)) +
geom_histogram(color="black", fill="blue") +
xlim(0,1000)+
labs(
title = ' \n
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
2.0    22.0    77.0   143.9   189.0  3409.0',
x = 'Call length'
)
?drop_na()
#write.csv(per_call_df, '~/Desktop/PAE/github/data/per_call_df.csv', row.names = FALSE)
#time to content 1
time_to_content<- dplyr::filter(log_data, grepl("INCOMING",logInfo)|grepl("CONTENT PLAYED",logInfo))
time_to_content<- time_to_content%>%
group_by(callId) %>%
mutate(to_content = eventTime - lag(eventTime))
time_to_content <-time_to_content %>%
group_by(callId) %>%
filter(row_number()==2)
ggplot(time_to_content , aes(x=to_content)) +
geom_histogram(color="black", fill="blue") +
xlim(0,400)+
labs(
title = ' \n
Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
2.0    22.0    77.0   143.9   189.0  3409.0',
x = 'time to content'
)
ggplot(per_call_per_caller, aes(x=n)) +
geom_histogram(color="black", fill="blue")+
xlim(0,50)
write.csv(per_call_df, '~/Desktop/PAE/github/data/per_call_df.csv', row.names = FALSE)
